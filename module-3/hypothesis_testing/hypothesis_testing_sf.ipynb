{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conducting T-Tests\n",
    "\n",
    "## Introduction\n",
    "Just as you previously used the t distribution to provide confidence intervals on estimating the population mean, you can also use similar methods to test whether two populations are different, statistically speaking. To do this, you can use a t-test.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "\n",
    "* Distinguish T-ditribution form normal distribution\n",
    "\n",
    "* Perform a complete one sample t-test analysis and describe the results\n",
    "\n",
    "\n",
    "\n",
    "## Hypothesis testing using the T-distribution\n",
    "\n",
    "In frequentist hypothesis testing, you construct a test statistic from the measured data and use the value of that statistic to decide whether to accept or reject the null hypothesis. \n",
    "The test statistic is a lower dimensional summary of the data but still maintains the discriminatory power necessary to make the decision whether or not to reject the null hypothesis.\n",
    "\n",
    "\n",
    "## t-test\n",
    "t-tests (also called Student’s t-test) are very practical hypotheses tests that can be employed to compare two averages (means) to know if they are different from each other. You should run a t-test when you either:\n",
    "* don’t know the population standard deviation \n",
    "* you have a small sample size    \n",
    "\n",
    "Like a z-test, the t-test also tells you how significant the differences are i.e. it lets you know if those differences could have happened by chance. In this lesson, you will get an introduction to t-tests, in particular, the 1-sample t-test. There are additional kinds of t-tests including 2-sample t-test and paired t-test. This lesson will show you the mathematical calculations behind a 1-sample t-test as well as how to perform a t-test in Python using NumPy and SciPy. \n",
    "\n",
    "Detailed descriptions of hypothesis testing with t-tests can be found [here](http://www.mas.ncl.ac.uk/~njnsm/medfac/docs/) and [here](http://blog.minitab.com/blog/adventures-in-statistics-2/understanding-t-tests-t-values-and-t-distributions)\n",
    "\n",
    "\n",
    "\n",
    "### One Sample t-test\n",
    "\n",
    "The 1-sample t-test is a statistical procedure used to determine whether a sample of observations could have been generated by a process with a specific mean. The one sample t-test compares the mean of your sample data to a known value. For example, you might want to know how your sample mean compares to the population mean.  Here is a quick example of a scenario where a 1-sample t-test could be applied. \n",
    "\n",
    "*Suppose you are interested in determining whether a bakery production line produces cakes with the weight of exactly 2 pounds. To test this hypothesis, you could collect a sample of cakes from the production line, measure their weights, and compare the sample with a value of 2 using a one-sample t-test.* \n",
    "\n",
    "### Two Sample t-tests\n",
    "\n",
    "The two-sample t-test is used to determine if two population means are equal. The main types of two-sampled t-tests are paired and independent tests. Paired Tests are useful for determining how different a sample is affected by a certain treatment. In other words, the individual items/people in the sample will remain the same and researchers are comparing how they change after treatment. Here is an example of a scenario where a two-sample paired t-test could be applied:\n",
    "\n",
    "*The US olympic weightlifting team is trying out a new workout techniques to in an attempt to improve everyone's powerlifting abilities. Did the program have an effect on a 95% significance level?*\n",
    "\n",
    "Because we are looking at how specific individuals were affected by a treatment, we would use the paired t-test.\n",
    "\n",
    "Independent two-sample t-tests are for when we are comparing two different, unrelated samples to one another. Unlike paired t-tests, we are not taking paired differences because there is no way to pair two unrelated samples! Here is an example of a scenario where a two-sample independent t-test could be applied:\n",
    "\n",
    "*Agricultural scientists are trying to compare the difference in soybean yields in two different counties of Mississippi.*\n",
    "\n",
    "You will learn more about the specifics of two sample t-tests in future lessons, but this lesson will focus on executing a one sample t-test.\n",
    "\n",
    "#### Regardless of the type of t-test you are performing, there are 5 main steps to executing them:\n",
    "\n",
    "1) Set up null and alternative hypotheses\n",
    "\n",
    "2) Choose a significance level \n",
    "\n",
    "3) Calculate the test statistic\n",
    "\n",
    "4) Determine the critical or p-value (find the rejection region)\n",
    "\n",
    "5) Compare t-value with critical t-value to accept or reject the Null hypothesis.\n",
    "\n",
    "\n",
    "Now, you're going to go through these 5 steps in more detail to complete a t-test.\n",
    "\n",
    "Let's begin with a sample experiment:\n",
    "\n",
    "### Sample question: \n",
    "\n",
    ">** *\"Acme Ltd. wants to improve sales performance. Past sales data indicate that the average sale was 100 dollars per transaction. After training the sales force, recent sales data (from a random sample of 25 salesmen) is shown below:\"* **\n",
    "\n",
    "       \n",
    "      [122.09, 100.64, 125.77, 120.32, 118.25,  \n",
    "        96.47, 111.4 ,  80.66, 110.77, 111.14, \n",
    "        102.9, 114.54,  88.09,  98.59,  87.07, \n",
    "       110.43, 101.9 , 123.89,  97.03, 116.23, \n",
    "        108.3, 112.82, 119.57, 131.38, 128.39]\n",
    "\n",
    "** Did the training work? **\n",
    "\n",
    "Before completing the hypothesis test, let's calculate some summary statistics to see if the mean of the sample differed a substantial amount from the population. After, you can check to ensure that the data is relatively normal.\n",
    "\n",
    "\n",
    "* **The population mean ($\\mu$).** Given as 100 (from past data).\n",
    "* **The sample mean ($\\bar{x}$).** Calculate from the sample data\n",
    "* **The sample standard deviation ($s$).** Calculate from sample data\n",
    "* **Number of observations($n$).** 25 as given in the question. This can also be calculated from the sample data.\n",
    "* **Degrees of Freedom($df$).** Calculate from the sample as df = total no. of observations - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Import the packages\n",
    "import numpy as np\n",
    "import scipy.stats as stats \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Seare\n"
     ]
    }
   ],
   "source": [
    "print('Hello Seare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seare\n"
     ]
    }
   ],
   "source": [
    "import sample\n",
    "sample.print_name('seare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample contains 25 observations, having a mean of 109.5456 and a standard deviation (sigma) =  13.338774643871902 , with 24 degrees of freedom. The difference between sample and population means is: -86.6612253561281\n"
     ]
    }
   ],
   "source": [
    "# For visualizing distributions - optional \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sample = np.array([122.09, 100.64, 125.77, 120.32, 118.25,  96.47, 111.4 , 80.66,\n",
    "       110.77, 111.14, 102.9 , 114.54,  88.09,  98.59,  87.07, 110.43,\n",
    "       101.9 , 123.89,  97.03, 116.23, 108.3 , 112.82, 119.57, 131.38,\n",
    "       128.39])\n",
    "\n",
    "\n",
    "# Population mean (μ)\n",
    "mu = 100\n",
    "\n",
    "# Sample mean (x̄) using NumPy mean()\n",
    "x_bar = sample.mean()\n",
    "\n",
    "# Sample Standard Deviation (sigma) using Numpy\n",
    "sigma = sample.std(ddof=1)\n",
    "\n",
    "\n",
    "# Sample size (n)\n",
    "n = len(sample)\n",
    "\n",
    "# Degrees of Freedom\n",
    "df = n-1\n",
    "\n",
    "# Difference in sample mean \n",
    "diff = sigma - mu\n",
    "\n",
    "\n",
    "# Print the findings\n",
    "print ('The sample contains', n, 'observations, having a mean of', x_bar, \"and a standard deviation (sigma) = \", sigma, \n",
    "       \", with\", df, 'degrees of freedom. The difference between sample and population means is:', diff)\n",
    "\n",
    "# The sample contains 25 observations, having a mean of 109.5456 \n",
    "# and a standard deviation (sigma) =  13.069276668584225 , \n",
    "# with 24 degrees of freedom. \n",
    "# The difference between sample and population means is: 9.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([122.09, 100.64, 125.77, 120.32, 118.25,  96.47, 111.4 , 80.66,\n",
    "       110.77, 111.14, 102.9 , 114.54,  88.09,  98.59,  87.07, 110.43,\n",
    "       101.9 , 123.89,  97.03, 116.23, 108.3 , 112.82, 119.57, 131.38,\n",
    "       128.39])\n",
    "x_bar = sample.mean()\n",
    "s = sample.std(ddof=1)\n",
    "s1  = np.std(sample, ddof=1)\n",
    "print(x_bar)\n",
    "print(s)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample mean is $9.54 per sale higher than the population mean, which indicates that at least superficially, the training program appears to have improved performance.\n",
    "\n",
    "Is the sample roughly normally distributed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "count = collections.Counter(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=sample, rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)\n",
    "sns.set(rc={'figure.figsize':(9,9)})\n",
    "sns.distplot(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Write your null and alternative hypothesis statements\n",
    "\n",
    "As you are trying to monitor a change in the sales performance after the training, the null-hypothesis addresses the fact that there is no change and sales performance before and after the training is exactly the same. \n",
    "\n",
    "__$H_{0}$: _The null hypothesis_ is that there is no difference in sales, so:__\n",
    "\n",
    "> $H_{0}: \\mu$ = $100.\n",
    "\n",
    "    \n",
    "This is the one that you are testing. Our alternate hypothesis should address the expected change in the sales performance i.e. the sales performance has increased and the mean of sales post-training is greater than 100. \n",
    "\n",
    "__$H_{1}$: _The alternative hypothesis_ is that there is a change i.e. the mean sales increased.__\n",
    "\n",
    "> $H_{1}: \\mu$ > $100.\n",
    "\n",
    "\n",
    "### Step 2: Choose a Significance Level (Alpha)\n",
    "\n",
    "\n",
    "The significance level, also denoted as alpha or `α`, is the probability of rejecting the null hypothesis when it is true. For example, a significance level of 0.05 indicates a 5% risk of concluding that a difference exists when there is no actual difference. Look at the following graphs for a better understanding: \n",
    "\n",
    "\n",
    "<img src=\"images/P05.png\" alt=\"drawing\" width=\"500px\"/>\n",
    "In the graph above, the two shaded areas are equidistant from the null hypothesis value and each area has a probability of 0.025, for a total of 0.05. In statistics, you call these shaded areas the critical regions for a two-tailed test. If the population mean is 260, you’d expect to obtain a sample mean that falls in the critical region 5% of the time. The critical region defines how far away our sample statistic must be from the null hypothesis value before you can say it is unusual enough to reject the null hypothesis.\n",
    "\n",
    "Our sample mean (330.6) falls within the critical region, which indicates it is statistically significant at the 0.05 level.\n",
    "\n",
    "You can also see if it is statistically significant using the other common significance level of 0.01.\n",
    "\n",
    "\n",
    "<img src=\"images/P01.png\" alt=\"drawing\" width=\"500px\"/>\n",
    "\n",
    "The two shaded areas each have a probability of 0.005, the two of which add up to a total probability of 0.01. This time the sample mean does not fall within the critical region, and you fail to reject the null hypothesis. This comparison shows why you need to choose your significance level before you begin your study. It protects you from choosing a significance level because it conveniently gives you significant results!\n",
    "\n",
    "Using the graph, data scientists are able to determine that their results are statistically significant at the 0.05 level without using a P value. However, when you use the numeric output produced by statistical software, you’ll need to compare the P value to your significance level to make this determination.\n",
    "\n",
    "### **For Acme's experiment, you can assume an $\\alpha$ of 0.05.**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the t-statistic\n",
    "\n",
    "The sample looks like a nicely shaped normal distribution. After fulfilling the three requirements for a t-test mentioned above i.e. normality, independence, and randomness, we are ready to calculate our t statistic using the formula for one-sample t-test given as:\n",
    "\n",
    "# $$t = \\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}}$$\n",
    " \n",
    "> Using the formula given above, calculate the t-value in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sigma\n",
    "t_stat = (x_bar -  mu)/(sigma/np.sqrt(n))\n",
    "t_stat\n",
    "# 3.578139767278185 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample generated a t-statistic of around 3.58. Where in the t-distribution is this located? Let's try visualizing the calculated t-statistic on top of a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points on the x axis between -5 and 5:\n",
    "xs = np.linspace(-5, 5, 200)\n",
    "\n",
    "# use stats.t.pdf to get values on the probability density function for the t-distribution\n",
    "# the second argument is the degrees of freedom\n",
    "ys = stats.t.pdf(xs, df)#, 0, 1)\n",
    "\n",
    "# initialize a matplotlib \"figure\"\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "# get the current \"axis\" out of the figure\n",
    "ax = fig.gca()\n",
    "\n",
    "# plot the lines using matplotlib's plot function:\n",
    "ax.plot(xs, ys, linewidth=3, color='darkblue')\n",
    "\n",
    "# plot a vertical line for our measured difference in rates t-statistic\n",
    "ax.axvline(t_stat, color='red', linestyle='--', lw=5,label='t-statistic')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate critical value (find rejection region)\n",
    "\n",
    "Note that a positive t value indicates that the sample mean is greater than the population mean and vice versa. This means that the sample's average sales performance post-training is greater than average population sales performance. \n",
    "\n",
    "This sounds like good news, **BUT** is the increase high enough to reject the null hypothesis and accept that there is a significant increase in the mean of post-training sales performance, or is it just by chance. It's possible to calculate a critical t-value with a t-table and also by using python `scipy.stats` module.\n",
    "\n",
    "\n",
    "The critical value approach involves determining \"likely\" or \"unlikely\", by determining whether or not the observed test statistic is more extreme than would be expected if the null hypothesis were true. This involves comparing the observed test statistic to some cutoff value, called the **\"critical value\"**. \n",
    ">If the test statistic is more extreme than the critical value, then the null hypothesis is rejected in favor of the alternative hypothesis. If the test statistic is not as extreme as the critical value, then the null hypothesis is not rejected.\n",
    "\n",
    "\n",
    "You need two values to find this:\n",
    "\n",
    "The **alpha level**: given as 5% in the question.\n",
    "\n",
    "**Degrees of freedom**, which is the number of items in the sample (n) minus 1: 25 – 1 = 24.\n",
    "\n",
    "![t-dist](images/t-dist.png)\n",
    "\n",
    "You use a one-tailed t-test towards the positive (right side of the t-distribution) to identify an increase in the sales performance. \n",
    "\n",
    "Look up 24 degrees of freedom in the left column and a p value of 0.05 (from 5% alpha level - 95% confidence level) in the top row. The intersection is `1.711`. This is our one-sample critical t-value.\n",
    "\n",
    "For the Null hypothesis to be true, what this critical value means is that you would expect most values to fall under 1.711. If your calculated t-value (from Step 4) falls within this range, the null hypothesis is likely true and you would fail to reject the null hypothesis.\n",
    "\n",
    "This value can also be calculated in Python using Scipy.stats module using ppf() (Percent Point Function) as `scipy.stats.t.ppf(1-alpha, df)`. \n",
    "\n",
    "Let's calculate the critical t using this formula and confirm our earlier findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate critical t value\n",
    "t_crit = np.round(stats.t.ppf(1 - 0.05, df=24),3)\n",
    "t_crit\n",
    "# 1.711\n",
    "# stats.norm.pdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the critical value returned from the function (rounded off 2 two decimal places) is the same as the one you should have found the in the t-distribution table i.e. 1.711. \n",
    "\n",
    "Using matplotlib, you can graph the rejection region as such. Any t-statistic that falls within the shaded region to the right will cause the hypothesis to be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points on the x axis between -5 and 5:\n",
    "xs = np.linspace(-5, 5, 200)\n",
    "\n",
    "# use stats.t.pdf to get values on the probability density function for the t-distribution\n",
    "# the second argument is the degrees of freedom\n",
    "ys = stats.t.pdf(xs, df, 0, 1)\n",
    "\n",
    "# initialize a matplotlib \"figure\"\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "# get the current \"axis\" out of the figure\n",
    "ax = fig.gca()\n",
    "\n",
    "# plot the lines using matplotlib's plot function:\n",
    "ax.plot(xs, ys, linewidth=3, color='darkblue')\n",
    "\n",
    "\n",
    "ax.axvline(t_crit,color='green',linestyle='--',lw=4,label='critical t-value')\n",
    "ax.legend()\n",
    "ax.fill_betweenx(ys,xs,t_crit,where= xs > t_crit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Compare t-value with critical t-value to accept or reject the Null Hypothesis\n",
    "\n",
    "Any t value which is greater than 1.711 will fall into the shaded region in the above figure. t-values greater than 1.711 would reflect an \"extreme\" result and can be used to reject the null hypothesis. \n",
    "\n",
    "Your calculated t-value, known as the t-statistic is 3.65, which is greater than 1.711 and hence the results can be called \"statistically significant\" and will allow researchers to reject the null hypothesis and with 95% confidence state that: \n",
    "\n",
    "*We are 95% sure that the mean sales performance post training is higher than the population mean prior to training.*\n",
    "\n",
    "**NOTE:** This calculation can also be performed using the `ttest_1samp`  function in `SciPy.stats` indicated here: \n",
    "\n",
    ">**scipy.stats.ttest_1samp(a, popmean, axis=0, nan_policy='propagate')**\n",
    "\n",
    "\n",
    "Where a is the sample mean ($\\bar{x}$) and popmean ($\\mu$) is the population mean. This function returns the t-value and p-value for the sample. Here, you are using a one-tailed t-test as you are looking for an increase in sales performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = stats.ttest_1samp(a= sample, popmean= mu)         \n",
    "print (\"The t-value for sample is\", round(results[0], 2), \"and the p-value is\", np.round((results[1]), 4))\n",
    "#  Print results\n",
    "# The t-value for sample is 3.58 and the p-value is 0.0015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use our null and alternate hypotheses defined earlier to state the results from our findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (results[0]>t_crit) and (results[1]<0.05):\n",
    "    print (\"Null hypothesis rejected. Results are statistically significant with t-value =\", \n",
    "           round(results[0], 2), \"and p-value =\", np.round((results[1]), 4))\n",
    "else:\n",
    "    print (\"Null hypothesis is Accepted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to visualize where the calculated t-statistic is compared to the critical t-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points on the x axis between -5 and 5:\n",
    "xs = np.linspace(-5, 5, 200)\n",
    "\n",
    "# use stats.t.pdf to get values on the probability density function for the t-distribution\n",
    "# the second argument is the degrees of freedom\n",
    "ys = stats.t.pdf(xs, df, 0, 1)\n",
    "\n",
    "# initialize a matplotlib \"figure\"\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "# get the current \"axis\" out of the figure\n",
    "ax = fig.gca()\n",
    "\n",
    "# plot the lines using matplotlib's plot function:\n",
    "ax.plot(xs, ys, linewidth=3, color='darkblue')\n",
    "\n",
    "# plot a vertical line for our measured difference in rates t-statistic\n",
    "ax.axvline(t, color='red', linestyle='--', lw=5,label='t-statistic')\n",
    "\n",
    "ax.axvline(t_crit,color='green',linestyle='--',lw=4,label='critical t-value')\n",
    "ax.fill_betweenx(ys,xs,t_crit,where= xs > t_crit)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, you saw a quick introduction to hypothesis testing using frequentists methods with t-values and p-values. You saw how a one sample t-test can be applied to contexts where the population mean is unknown and you have a limited amount of sample data. You looked at all the stages required for such hypothesis testing with a description of steps and also, how to perform these steps in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([122.09, 100.64, 125.77, 120.32, 118.25,  96.47, 111.4 , 80.66,\n",
    "       110.77, 111.14, 102.9 , 114.54,  88.09,  98.59,  87.07, 110.43,\n",
    "       101.9 , 123.89,  97.03, 116.23, 108.3 , 112.82, 119.57, 131.38,\n",
    "       128.39])\n",
    "mu = 100\n",
    "df = len(sample) - 1\n",
    "x_bar = sample.mean()\n",
    "sd = sample.std(ddof=1)\n",
    "alpha = 0.05\n",
    "t_stat = (x_bar - mu)/(sd/math.sqrt(len(sample)))\n",
    "t_crit = stats.t.ppf(1-alpha, df)\n",
    "xs = np.linspace(start=-5, stop=5, num=200)\n",
    "ys = stats.t.pdf(xs, df)# 0, 1)\n",
    "# ys = stats.norm.pdf(x=xs, loc=x_bar, scale=sd)\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "ax = fig.gca()\n",
    "ax.plot(xs, ys, linewidth=3, color='darkblue')\n",
    "ax.axvline(t_stat, color='red', linestyle='--', lw=5,label='t-statistic')\n",
    "ax.axvline(t_crit,color='green',linestyle='--',lw=4,label='critical t-value')\n",
    "ax.fill_betweenx(ys,xs,t_crit,where= xs > t_crit)\n",
    "plt.title('Right-sided t-distibution', size=20)\n",
    "plt.xlabel('t (p, df)', size=15)\n",
    "plt.ylabel('Distribution', size=15)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "results = stats.ttest_1samp(a=sample, popmean= mu)  \n",
    "if (results[0]>t_crit) and (results[1]<0.05):\n",
    "    print (\"Null hypothesis rejected.\" + '\\n' + \"Results are statistically significant with t-value =\", \n",
    "           round(results[0], 2), \"and p-value =\", np.round((results[1]), 4))\n",
    "else:\n",
    "    print (\"Null hypothesis is Accepted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
